# DeepLearning

markdown 文件貌似有一些现实问题，clone 到本地之后可以看

Paper Lists:

+ [BetaVAE]: [https://openreview.net/pdf?id=Sy2fzU9gl] [vae]
+ [BeyondShortSnippets]: [https://arxiv.org/abs/1503.08909.pdf] [video] [classification]
+ [BiPointNet]: [https://arxiv.org/pdf/2010.05501.pdf] [3d vision]
+ [c3d]: [https://arxiv.org/pdf/1412.0767.pdf] [video] [classification]
+ [channel-aware fl] [https://arxiv.org/pdf/2004.00490.pdf] [federate learning]w
+ [ComprehensiveVideoReview]: [https://arxiv.org/pdf/2012.06567.pdf] [video] [review]
+ [ConvolutionalFusion]: [https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Feichtenhofer_Convolutional_Two-Stream_Network_CVPR_2016_paper.pdf] [video] [classoification]
+ [danet]: [https://openaccess.thecvf.com/content_ICCV_2019/papers/Xue_DANet_Divergent_Activation_for_Weakly_Supervised_Object_Localization_ICCV_2019_paper.pdf] [weakly supervised] [object localization] [segmentation] 
+ [danet]: [https://arxiv.org/abs/1809.02983.pdf] [segmentation]
+ [dcn]: [https://arxiv.org/abs/1708.05123.pdf] [recommendation system]
+ [dcn_v2]: [https://arxiv.org/pdf/2008.13535.pdf] [recommendation system]
+ [deepfm]: [https://www.ijcai.org/proceedings/2017/0239.pdf] [recommendation system]
+ [deepvideo]: [https://cs.stanford.edu/people/karpathy/deepvideo/deepvideo_cvpr2014.pdf] [video]
+ [deformable detr]: [https://arxiv.org/abs/2010.04159] [object detection] [transformer]
+ [detr]: [https://arxiv.org/pdf/2005.12872v3.pdf] [object detection] [transformer]
+ [dynamic detr]: [https://openaccess.thecvf.com/content/ICCV2021/papers/Dai_Dynamic_DETR_End-to-End_Object_Detection_With_Dynamic_Attention_ICCV_2021_paper.pdf] [object detection]
+ [efficient detr]: [https://arxiv.org/pdf/2104.01318.pdf] [object detection]
+ [FaceShifter]: [https://arxiv.org/pdf/1912.13457.pdf] [face generator] [gan] [unet]
+ [FactorVAE]: [https://arxiv.org/pdf/1802.05983.pdf] [vae] [factor]
+ [FM]: [https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf] [recommendation system]
+ [fintabnet]: [https://openaccess.thecvf.com/content/WACV2021/papers/Zheng_Global_Table_Extractor_GTE_A_Framework_for_Joint_Table_Identification_WACV_2021_paper.pdf] [table]
+ [i3d]: [https://arxiv.org/abs/1705.07750.pdf] [3d vision] [video]
+ [Imperfect IL]: [https://arxiv.org/pdf/2103.05910.pdf] [imitation learning]
+ [non local]: [https://arxiv.org/pdf/1711.07971.pdf] [video] [segmentation]
+ [PointNet]: [https://arxiv.org/pdf/1612.00593.pdf] [3d vision] [classification] [segmentation]
+ [PointNet++]: [https://arxiv.org/abs/1706.02413.pdf] [3d vision] [classification] [segmentation]
+ [pubtabnet]: [https://arxiv.org/pdf/1911.10683.pdf] [table]
+ [Query2Label]: [https://arxiv.org/pdf/2107.10834v1.pdf] [classification] [multi-label]
+ [r2+1d]: [https://arxiv.org/pdf/1711.11248v3.pdf] [video] 
+ [rcnn]: [object detection]
+ [segmenter]: [https://arxiv.org/abs/2105.05633.pdf] [segmentation]
+ [setr]: [https://arxiv.org/abs/2012.15840] [segmentation]
+ [SlowFast]: [https://arxiv.org/abs/1812.03982.pdf] [video] [classification]
+ [svm] [machine learning]
+ [tablebank] [https://arxiv.org/abs/1903.01949] [table]
+ [TableFormer] [https://arxiv.org/pdf/2203.01017.pdf] [table]
+ [tc_mdp] [https://arxiv.org/pdf/2004.11555.pdf] [mdp]
+ [timesformer]: [https://arxiv.org/abs/2102.05095v4] [video] [classification]
+ [tsn]: [https://arxiv.org/abs/1608.00859.pdf] [video] [classification]
+ [TwoStream]: [https://arxiv.org/abs/1406.2199.pdf] [video] [optical flow]
+ [vae]: [https://arxiv.org/pdf/1312.6114.pdf] [vae]
+ [vilt]: [https://arxiv.org/pdf/2102.03334.pdf] [multimodel]
+ [xnor]: [https://arxiv.org/abs/1603.05279.pdf] [model compression]
